{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "720541b0-3536-4131-9324-ab73e67dab4b",
   "metadata": {},
   "source": [
    "<h1><center>Image classification using a CNN</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c3752b-ccbf-4f3f-8fa9-6171b1c74cba",
   "metadata": {},
   "source": [
    "We first import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a89ead4d-869c-48e3-9c37-2fd7003662c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import requests, io, zipfile\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense, Dropout, ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f596c5a-d02a-4289-9b69-4406f0fbd327",
   "metadata": {},
   "source": [
    "We then download and extract the data we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67e5a3f6-ecdb-4733-8258-c46f8d390cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('res'):\n",
    "    train_req = requests.get('https://btsd.ethz.ch/shareddata/BelgiumTSC/BelgiumTSC_Training.zip')\n",
    "    test_req = requests.get('https://btsd.ethz.ch/shareddata/BelgiumTSC/BelgiumTSC_Testing.zip')\n",
    "    files = zipfile.ZipFile(io.BytesIO(train_req.content))\n",
    "    files.extractall('res')\n",
    "    files = zipfile.ZipFile(io.BytesIO(test_req.content))\n",
    "    files.extractall('res')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ee1127-d776-4cef-a031-39301cb3a81f",
   "metadata": {},
   "source": [
    "We will then create our datasets using the ImageDataGenerator tensorflow provides. For our train data we will also augment out data in order to further increase the model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f08e4def-1037-4890-826a-027576dc23ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'res/Training'\n",
    "test_dir = 'res/Testing'\n",
    "\n",
    "train_data_generator = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,   \n",
    "    height_shift_range=0.1,   \n",
    "    shear_range=0.1,          \n",
    "    zoom_range=0.1,           \n",
    "    horizontal_flip=True,     \n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2,\n",
    "    rescale=1./255\n",
    ")\n",
    "validation_data_generator = ImageDataGenerator(validation_split=0.2, rescale=1./255)\n",
    "test_data_generator = ImageDataGenerator(validation_split=0.2, rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c29698-999e-4c03-aca9-3c1948866fcb",
   "metadata": {},
   "source": [
    "After creating the generators, we will create the datasets. Its useful to note that we will use the grayscale color mode and a very low resolution in order to read the images in a sufficient data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2527858c-7977-4109-82e3-ded0823a0c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3683 images belonging to 62 classes.\n",
      "Found 892 images belonging to 62 classes.\n",
      "Found 2520 images belonging to 62 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_data_generator.flow_from_directory(train_dir,\n",
    "                                                        batch_size=32,\n",
    "                                                        class_mode='categorical',\n",
    "                                                        color_mode='grayscale',\n",
    "                                                        target_size=(56,56),\n",
    "                                                        subset='training')\n",
    "\n",
    "validation_dataset = validation_data_generator.flow_from_directory(train_dir,\n",
    "                                                        batch_size=32,\n",
    "                                                        class_mode='categorical',\n",
    "                                                        color_mode='grayscale',\n",
    "                                                        target_size=(56,56),\n",
    "                                                        subset='validation')\n",
    "\n",
    "test_dataset =  test_data_generator.flow_from_directory(test_dir,\n",
    "                                                  batch_size=32,\n",
    "                                                  class_mode  = 'categorical',\n",
    "                                                  color_mode='grayscale',\n",
    "                                                  target_size=(56,56))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc53496a-2360-419c-84c3-d4a28fd867ca",
   "metadata": {},
   "source": [
    "Now, we will create and compile our models. We will start with the custom one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ecc1a952-18e4-4d96-aed9-a81708df8741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_38 (Conv2D)          (None, 56, 56, 16)        416       \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 56, 56, 32)        12832     \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 56, 56, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 56, 56, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 28, 28, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 28, 28, 32)        25632     \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 28, 28, 16)        12816     \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 28, 28, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 28, 28, 16)        0         \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 14, 14, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 14, 14, 16)        0         \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 14, 14, 16)        6416      \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 14, 14, 8)         3208      \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 14, 14, 8)        32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 14, 14, 8)         0         \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 14, 14, 8)         0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 1568)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 200)               313800    \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 62)                12462     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 387,806\n",
      "Trainable params: 387,694\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(Conv2D(16, (5, 5), strides=(1, 1), activation=None, padding='same', input_shape=(56, 56, 1)))\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(32, (5, 5), activation=None, padding='same'))\n",
    "model.add(Conv2D(16, (5, 5), activation=None, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(16, (5, 5), activation=None, padding='same'))\n",
    "model.add(Conv2D(8, (5, 5), activation=None, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(62, activation='softmax'))\n",
    "model.compile(optimizer= tf.keras.optimizers.Adam(),\n",
    "            loss = 'categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abab8a7-0e6f-4371-b07e-fb356880a1fa",
   "metadata": {},
   "source": [
    "It is time to train the model and check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7a4b7ea-4e08-4b80-bd62-386113b956d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "116/116 [==============================] - 4s 25ms/step - loss: 2.9163 - accuracy: 0.3065 - val_loss: 2.3403 - val_accuracy: 0.4238\n",
      "Epoch 2/100\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 1.7753 - accuracy: 0.5300 - val_loss: 1.8621 - val_accuracy: 0.4832\n",
      "Epoch 3/100\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 1.2889 - accuracy: 0.6364 - val_loss: 1.0374 - val_accuracy: 0.7354\n",
      "Epoch 4/100\n",
      "116/116 [==============================] - 3s 23ms/step - loss: 1.0583 - accuracy: 0.6967 - val_loss: 0.6108 - val_accuracy: 0.8094\n",
      "Epoch 5/100\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.9193 - accuracy: 0.7206 - val_loss: 0.6595 - val_accuracy: 0.8038\n",
      "Epoch 6/100\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.7887 - accuracy: 0.7559 - val_loss: 0.5105 - val_accuracy: 0.8408\n",
      "Epoch 7/100\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.6881 - accuracy: 0.7793 - val_loss: 0.6551 - val_accuracy: 0.7724\n",
      "Epoch 8/100\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.6837 - accuracy: 0.7890 - val_loss: 0.4601 - val_accuracy: 0.8509\n",
      "Epoch 9/100\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.5866 - accuracy: 0.8154 - val_loss: 0.3493 - val_accuracy: 0.8778\n",
      "Epoch 10/100\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.5250 - accuracy: 0.8292 - val_loss: 0.3696 - val_accuracy: 0.8834\n",
      "Epoch 11/100\n",
      "116/116 [==============================] - 3s 21ms/step - loss: 0.5750 - accuracy: 0.8143 - val_loss: 0.3754 - val_accuracy: 0.8868\n",
      "Epoch 12/100\n",
      "116/116 [==============================] - 3s 21ms/step - loss: 0.4908 - accuracy: 0.8412 - val_loss: 0.2823 - val_accuracy: 0.9114\n",
      "Epoch 13/100\n",
      "116/116 [==============================] - 3s 23ms/step - loss: 0.4835 - accuracy: 0.8477 - val_loss: 0.3017 - val_accuracy: 0.9047\n",
      "Epoch 14/100\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.4376 - accuracy: 0.8566 - val_loss: 0.3060 - val_accuracy: 0.9114\n",
      "Epoch 15/100\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 0.4141 - accuracy: 0.8604 - val_loss: 0.2861 - val_accuracy: 0.9058\n",
      "Epoch 16/100\n",
      "116/116 [==============================] - 3s 23ms/step - loss: 0.4093 - accuracy: 0.8602 - val_loss: 0.2806 - val_accuracy: 0.9013\n",
      "Epoch 17/100\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.4197 - accuracy: 0.8675 - val_loss: 0.5547 - val_accuracy: 0.8453\n",
      "Epoch 18/100\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 0.4044 - accuracy: 0.8702 - val_loss: 0.4752 - val_accuracy: 0.8554\n",
      "Epoch 19/100\n",
      "116/116 [==============================] - 3s 23ms/step - loss: 0.3776 - accuracy: 0.8716 - val_loss: 0.2978 - val_accuracy: 0.9036\n",
      "Epoch 20/100\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.3576 - accuracy: 0.8813 - val_loss: 0.2392 - val_accuracy: 0.9170\n",
      "Epoch 21/100\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 0.3271 - accuracy: 0.8889 - val_loss: 0.2422 - val_accuracy: 0.9215\n",
      "Epoch 22/100\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.3149 - accuracy: 0.8887 - val_loss: 0.3370 - val_accuracy: 0.9025\n",
      "Epoch 23/100\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.3099 - accuracy: 0.8933 - val_loss: 0.2596 - val_accuracy: 0.9226\n",
      "Epoch 24/100\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 0.2866 - accuracy: 0.9052 - val_loss: 0.3126 - val_accuracy: 0.9013\n",
      "Epoch 25/100\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.3693 - accuracy: 0.8773 - val_loss: 0.2736 - val_accuracy: 0.9081\n",
      "Epoch 26/100\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 0.2863 - accuracy: 0.9055 - val_loss: 0.2801 - val_accuracy: 0.9058\n",
      "Epoch 27/100\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.2994 - accuracy: 0.9004 - val_loss: 0.3244 - val_accuracy: 0.8890\n",
      "Epoch 28/100\n",
      "116/116 [==============================] - 3s 23ms/step - loss: 0.2792 - accuracy: 0.9052 - val_loss: 0.2854 - val_accuracy: 0.9204\n",
      "Epoch 29/100\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.2692 - accuracy: 0.9088 - val_loss: 0.2564 - val_accuracy: 0.9182\n",
      "Epoch 30/100\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 0.3065 - accuracy: 0.8993 - val_loss: 0.2985 - val_accuracy: 0.9114\n",
      "Epoch 31/100\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.2596 - accuracy: 0.9074 - val_loss: 0.2310 - val_accuracy: 0.9327\n",
      "Epoch 32/100\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.2451 - accuracy: 0.9172 - val_loss: 0.2127 - val_accuracy: 0.9170\n",
      "Epoch 33/100\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.2431 - accuracy: 0.9142 - val_loss: 0.2181 - val_accuracy: 0.9215\n",
      "Epoch 34/100\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 0.2589 - accuracy: 0.9099 - val_loss: 0.3995 - val_accuracy: 0.8980\n",
      "Epoch 35/100\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.2338 - accuracy: 0.9232 - val_loss: 0.2506 - val_accuracy: 0.9182\n",
      "Epoch 36/100\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.2790 - accuracy: 0.9085 - val_loss: 0.2330 - val_accuracy: 0.9193\n",
      "Epoch 37/100\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.2425 - accuracy: 0.9142 - val_loss: 0.2223 - val_accuracy: 0.9114\n",
      "Epoch 38/100\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 0.2312 - accuracy: 0.9204 - val_loss: 0.2743 - val_accuracy: 0.9070\n",
      "Epoch 39/100\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 0.2132 - accuracy: 0.9177 - val_loss: 0.2282 - val_accuracy: 0.9316\n",
      "Epoch 40/100\n",
      "116/116 [==============================] - 3s 23ms/step - loss: 0.2438 - accuracy: 0.9196 - val_loss: 0.2355 - val_accuracy: 0.9182\n",
      "Epoch 41/100\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.2123 - accuracy: 0.9261 - val_loss: 0.2319 - val_accuracy: 0.9395\n",
      "Epoch 42/100\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 0.1983 - accuracy: 0.9299 - val_loss: 0.2468 - val_accuracy: 0.9316\n",
      "Epoch 43/100\n",
      "116/116 [==============================] - 3s 23ms/step - loss: 0.2071 - accuracy: 0.9346 - val_loss: 0.2973 - val_accuracy: 0.9058\n",
      "Epoch 44/100\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.1958 - accuracy: 0.9359 - val_loss: 0.2163 - val_accuracy: 0.9283\n",
      "Epoch 45/100\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.1804 - accuracy: 0.9422 - val_loss: 0.2329 - val_accuracy: 0.9249\n",
      "Epoch 46/100\n",
      "116/116 [==============================] - 3s 23ms/step - loss: 0.1902 - accuracy: 0.9318 - val_loss: 0.2638 - val_accuracy: 0.9283\n",
      "Epoch 47/100\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.1940 - accuracy: 0.9327 - val_loss: 0.2305 - val_accuracy: 0.9339\n",
      "Epoch 48/100\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 0.1849 - accuracy: 0.9327 - val_loss: 0.2371 - val_accuracy: 0.9283\n",
      "Epoch 49/100\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.1868 - accuracy: 0.9351 - val_loss: 0.2627 - val_accuracy: 0.9226\n",
      "Epoch 50/100\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.1842 - accuracy: 0.9392 - val_loss: 0.2565 - val_accuracy: 0.9182\n",
      "Epoch 51/100\n",
      "116/116 [==============================] - 3s 23ms/step - loss: 0.2005 - accuracy: 0.9357 - val_loss: 0.2976 - val_accuracy: 0.9036\n",
      "Epoch 52/100\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.2187 - accuracy: 0.9237 - val_loss: 0.2806 - val_accuracy: 0.9193\n",
      "Epoch 53/100\n",
      "116/116 [==============================] - 3s 23ms/step - loss: 0.1694 - accuracy: 0.9433 - val_loss: 0.2527 - val_accuracy: 0.9238\n",
      "Epoch 54/100\n",
      "116/116 [==============================] - 3s 23ms/step - loss: 0.1689 - accuracy: 0.9479 - val_loss: 0.2162 - val_accuracy: 0.9294\n",
      "Epoch 55/100\n",
      "116/116 [==============================] - 3s 23ms/step - loss: 0.1752 - accuracy: 0.9446 - val_loss: 0.2323 - val_accuracy: 0.9226\n",
      "Epoch 56/100\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.1885 - accuracy: 0.9359 - val_loss: 0.2246 - val_accuracy: 0.9383\n",
      "Epoch 57/100\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.2282 - accuracy: 0.9248 - val_loss: 0.2618 - val_accuracy: 0.9159\n"
     ]
    }
   ],
   "source": [
    "callbacks = []\n",
    "\n",
    "save_best_callback = tf.keras.callbacks.ModelCheckpoint(f'custom_model_weights.hdf5', save_best_only=True, verbose=0)\n",
    "callbacks.append(save_best_callback)\n",
    "\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(patience=25, restore_best_weights=True, verbose=0)\n",
    "callbacks.append(early_stop_callback)\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                              validation_data=validation_dataset,\n",
    "                              steps_per_epoch=len(train_dataset),\n",
    "                              epochs=100,\n",
    "                              validation_steps=len(validation_dataset),\n",
    "                              verbose=1,\n",
    "                              callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c2d7097-4dee-4096-be67-afa2b83818d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 15s 192ms/step - loss: 0.2323 - accuracy: 0.9429\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2bb348-3f7c-4439-8a6f-8b394a201249",
   "metadata": {},
   "source": [
    "As we can see we have a very accurate model for our dataset. Also, the test accuracy is on part with the training accuracy, suggesting we have no overfitting or underfitting. How will this model perform if we use it in conjuction with a pretrained model tho? We will use the MobileNetV2 pretrained model as we use quite low resolution images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d682ade-7d6c-40aa-a30f-a620cfb99a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3683 images belonging to 62 classes.\n",
      "Found 892 images belonging to 62 classes.\n",
      "Found 2520 images belonging to 62 classes.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from keras.applications import MobileNetV2\n",
    "gc.collect()\n",
    "\n",
    "train_dataset_rgb = train_data_generator.flow_from_directory(train_dir,\n",
    "                                                        batch_size=32,\n",
    "                                                        class_mode='categorical',\n",
    "                                                        color_mode='rgb',\n",
    "                                                        target_size=(56,56),\n",
    "                                                        subset='training')\n",
    "\n",
    "validation_dataset_rgb = validation_data_generator.flow_from_directory(train_dir,\n",
    "                                                        batch_size=32,\n",
    "                                                        class_mode='categorical',\n",
    "                                                        color_mode='rgb',\n",
    "                                                        target_size=(56,56),\n",
    "                                                        subset='validation')\n",
    "\n",
    "test_dataset_rgb =  test_data_generator.flow_from_directory(test_dir,\n",
    "                                                  batch_size=32,\n",
    "                                                  class_mode  = 'categorical',\n",
    "                                                  color_mode='rgb',\n",
    "                                                  target_size=(56,56))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af50a40-d0f7-484d-ac4a-0a344dbb53f0",
   "metadata": {},
   "source": [
    "For the pretrained model we want to test how our custom model will work as the top part of our pretrained weights. For that reason we will freeze all base weights except a few. As the pretrained weights might not be trained for our specific dataset, we will expect a slower accuracy increase through the epochs, and potentially a lower final accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d73cb198-067c-49b1-a913-f2c632e88b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 56, 56, 3)]       0         \n",
      "                                                                 \n",
      " mobilenetv2_1.00_224 (Funct  (None, 2, 2, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 2, 2, 16)          512016    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 2, 2, 16)         64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 2, 2, 16)          0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 1, 1, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1, 1, 16)          0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 1, 1, 32)          12832     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 1, 1, 16)          12816     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 1, 1, 16)         64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 1, 1, 16)          0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 1, 1, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, 1, 16)          0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 1, 1, 16)          6416      \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 1, 1, 8)           3208      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 1, 1, 8)          32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_4 (ReLU)              (None, 1, 1, 8)           0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, 1, 8)           0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 200)               1800      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 62)                12462     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,819,694\n",
      "Trainable params: 1,281,630\n",
      "Non-trainable params: 1,538,064\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretrained_base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(56, 56, 3))\n",
    "#pretrained_base_model.trainable = False\n",
    "pretrained_base_model.trainable = True\n",
    "for layer in pretrained_base_model.layers[:-5]:\n",
    "    layer.trainable = False\n",
    "input_layer = tf.keras.layers.Input(shape=(56, 56, 3))\n",
    "x = pretrained_base_model(input_layer)\n",
    "x = Conv2D(16, (5, 5), strides=(1, 1), activation=None, padding='same', input_shape=(56, 56, 3))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "#Custom Convolutional Layer 2\n",
    "x = Conv2D(32, (5, 5), activation=None, padding='same')(x)\n",
    "x = Conv2D(16, (5, 5), activation=None, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "# Custom Convolutional Layer 3\n",
    "x = Conv2D(16, (5, 5), activation=None, padding='same')(x)\n",
    "x = Conv2D(8, (5, 5), activation=None, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "# Step 6: Flatten and add Dense layers for final classification\n",
    "x = Flatten()(x)\n",
    "x = Dense(200, activation='relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "output = Dense(62, activation='softmax')(x)\n",
    "\n",
    "# Step 7: Create the complete model\n",
    "model = Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "# Step 8: Compile the model\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 9: Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a78bb7-23e2-4931-8a59-04268f1c33c2",
   "metadata": {},
   "source": [
    "The only difference between the process of the model creations is the learning rate. We use SGD instead of Adam. The reason is because of the greater amount of trainable weights as well as the existence of non trainable weights, the model may need to adjust the learning rate dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a909372-1d65-4cd6-970a-3cc2de397728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "116/116 [==============================] - 8s 48ms/step - loss: 3.4768 - accuracy: 0.2034 - val_loss: 3.5446 - val_accuracy: 0.1928\n",
      "Epoch 2/100\n",
      "116/116 [==============================] - 5s 40ms/step - loss: 2.7022 - accuracy: 0.2930 - val_loss: 2.7312 - val_accuracy: 0.3128\n",
      "Epoch 3/100\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 2.4015 - accuracy: 0.3739 - val_loss: 2.6066 - val_accuracy: 0.3587\n",
      "Epoch 4/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 2.2283 - accuracy: 0.4021 - val_loss: 2.7121 - val_accuracy: 0.3576\n",
      "Epoch 5/100\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 2.1054 - accuracy: 0.4295 - val_loss: 2.3946 - val_accuracy: 0.3733\n",
      "Epoch 6/100\n",
      "116/116 [==============================] - 6s 49ms/step - loss: 2.0018 - accuracy: 0.4363 - val_loss: 2.3823 - val_accuracy: 0.4316\n",
      "Epoch 7/100\n",
      "116/116 [==============================] - 5s 40ms/step - loss: 1.9348 - accuracy: 0.4602 - val_loss: 2.5299 - val_accuracy: 0.3935\n",
      "Epoch 8/100\n",
      "116/116 [==============================] - 5s 40ms/step - loss: 1.8846 - accuracy: 0.4708 - val_loss: 2.1047 - val_accuracy: 0.4552\n",
      "Epoch 9/100\n",
      "116/116 [==============================] - 5s 43ms/step - loss: 1.8536 - accuracy: 0.4692 - val_loss: 1.8119 - val_accuracy: 0.5168\n",
      "Epoch 10/100\n",
      "116/116 [==============================] - 4s 39ms/step - loss: 1.7487 - accuracy: 0.4876 - val_loss: 2.5077 - val_accuracy: 0.3845\n",
      "Epoch 11/100\n",
      "116/116 [==============================] - 4s 39ms/step - loss: 1.9496 - accuracy: 0.4434 - val_loss: 3.3944 - val_accuracy: 0.2085\n",
      "Epoch 12/100\n",
      "116/116 [==============================] - 5s 40ms/step - loss: 1.9112 - accuracy: 0.4488 - val_loss: 2.0642 - val_accuracy: 0.3845\n",
      "Epoch 13/100\n",
      "116/116 [==============================] - 5s 40ms/step - loss: 1.8184 - accuracy: 0.4705 - val_loss: 1.7704 - val_accuracy: 0.4585\n",
      "Epoch 14/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 1.7291 - accuracy: 0.4882 - val_loss: 2.0066 - val_accuracy: 0.4238\n",
      "Epoch 15/100\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 1.7785 - accuracy: 0.4817 - val_loss: 11.4024 - val_accuracy: 0.2074\n",
      "Epoch 16/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 1.7504 - accuracy: 0.4716 - val_loss: 2.7011 - val_accuracy: 0.3901\n",
      "Epoch 17/100\n",
      "116/116 [==============================] - 4s 37ms/step - loss: 1.7059 - accuracy: 0.4836 - val_loss: 2.1047 - val_accuracy: 0.3935\n",
      "Epoch 18/100\n",
      "116/116 [==============================] - 5s 40ms/step - loss: 1.6439 - accuracy: 0.5045 - val_loss: 2.4724 - val_accuracy: 0.4025\n",
      "Epoch 19/100\n",
      "116/116 [==============================] - 4s 37ms/step - loss: 1.6312 - accuracy: 0.5067 - val_loss: 2.3655 - val_accuracy: 0.4148\n",
      "Epoch 20/100\n",
      "116/116 [==============================] - 5s 40ms/step - loss: 1.7697 - accuracy: 0.4746 - val_loss: 1.6179 - val_accuracy: 0.5202\n",
      "Epoch 21/100\n",
      "116/116 [==============================] - 5s 39ms/step - loss: 1.6151 - accuracy: 0.5159 - val_loss: 2.0907 - val_accuracy: 0.4910\n",
      "Epoch 22/100\n",
      "116/116 [==============================] - 5s 39ms/step - loss: 1.6245 - accuracy: 0.5137 - val_loss: 1.3594 - val_accuracy: 0.5661\n",
      "Epoch 23/100\n",
      "116/116 [==============================] - 5s 39ms/step - loss: 1.5388 - accuracy: 0.5341 - val_loss: 1.1792 - val_accuracy: 0.5953\n",
      "Epoch 24/100\n",
      "116/116 [==============================] - 5s 40ms/step - loss: 1.5513 - accuracy: 0.5324 - val_loss: 1.2153 - val_accuracy: 0.6099\n",
      "Epoch 25/100\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 1.5594 - accuracy: 0.5235 - val_loss: 1.1116 - val_accuracy: 0.6132\n",
      "Epoch 26/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 1.5209 - accuracy: 0.5295 - val_loss: 1.3083 - val_accuracy: 0.5897\n",
      "Epoch 27/100\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 1.5244 - accuracy: 0.5371 - val_loss: 1.2313 - val_accuracy: 0.6110\n",
      "Epoch 28/100\n",
      "116/116 [==============================] - 5s 39ms/step - loss: 1.4763 - accuracy: 0.5441 - val_loss: 1.3411 - val_accuracy: 0.6121\n",
      "Epoch 29/100\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 1.4727 - accuracy: 0.5428 - val_loss: 1.0850 - val_accuracy: 0.6222\n",
      "Epoch 30/100\n",
      "116/116 [==============================] - 5s 40ms/step - loss: 1.3924 - accuracy: 0.5694 - val_loss: 1.1026 - val_accuracy: 0.6345\n",
      "Epoch 31/100\n",
      "116/116 [==============================] - 5s 40ms/step - loss: 1.4149 - accuracy: 0.5610 - val_loss: 1.0678 - val_accuracy: 0.6491\n",
      "Epoch 32/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 1.4493 - accuracy: 0.5577 - val_loss: 1.1503 - val_accuracy: 0.6267\n",
      "Epoch 33/100\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 1.4364 - accuracy: 0.5631 - val_loss: 1.0679 - val_accuracy: 0.6424\n",
      "Epoch 34/100\n",
      "116/116 [==============================] - 5s 39ms/step - loss: 1.4783 - accuracy: 0.5558 - val_loss: 1.7074 - val_accuracy: 0.4888\n",
      "Epoch 35/100\n",
      "116/116 [==============================] - 5s 40ms/step - loss: 1.6509 - accuracy: 0.5186 - val_loss: 4.5517 - val_accuracy: 0.1166\n",
      "Epoch 36/100\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 1.8466 - accuracy: 0.4657 - val_loss: 1.6556 - val_accuracy: 0.5247\n",
      "Epoch 37/100\n",
      "116/116 [==============================] - 4s 37ms/step - loss: 1.6435 - accuracy: 0.5067 - val_loss: 1.4385 - val_accuracy: 0.5706\n",
      "Epoch 38/100\n",
      "116/116 [==============================] - 4s 37ms/step - loss: 1.5869 - accuracy: 0.5259 - val_loss: 1.2067 - val_accuracy: 0.6065\n",
      "Epoch 39/100\n",
      "116/116 [==============================] - 5s 40ms/step - loss: 1.7329 - accuracy: 0.4871 - val_loss: 2.3017 - val_accuracy: 0.4305\n",
      "Epoch 40/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 1.6140 - accuracy: 0.5153 - val_loss: 1.5841 - val_accuracy: 0.5258\n",
      "Epoch 41/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 1.5383 - accuracy: 0.5436 - val_loss: 1.6487 - val_accuracy: 0.5392\n",
      "Epoch 42/100\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 1.5129 - accuracy: 0.5316 - val_loss: 1.3496 - val_accuracy: 0.5852\n",
      "Epoch 43/100\n",
      "116/116 [==============================] - 5s 39ms/step - loss: 1.4886 - accuracy: 0.5515 - val_loss: 1.5041 - val_accuracy: 0.5516\n",
      "Epoch 44/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 1.4952 - accuracy: 0.5528 - val_loss: 1.3705 - val_accuracy: 0.5673\n",
      "Epoch 45/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 1.4666 - accuracy: 0.5539 - val_loss: 4.0730 - val_accuracy: 0.3285\n",
      "Epoch 46/100\n",
      "116/116 [==============================] - 5s 39ms/step - loss: 1.5769 - accuracy: 0.5259 - val_loss: 2.7875 - val_accuracy: 0.3812\n",
      "Epoch 47/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 1.4809 - accuracy: 0.5539 - val_loss: 1.6891 - val_accuracy: 0.4966\n",
      "Epoch 48/100\n",
      "116/116 [==============================] - 5s 40ms/step - loss: 1.4292 - accuracy: 0.5639 - val_loss: 1.2101 - val_accuracy: 0.6043\n",
      "Epoch 49/100\n",
      "116/116 [==============================] - 5s 39ms/step - loss: 1.4178 - accuracy: 0.5642 - val_loss: 1.1322 - val_accuracy: 0.6289\n",
      "Epoch 50/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 1.4208 - accuracy: 0.5610 - val_loss: 1.2374 - val_accuracy: 0.6099\n",
      "Epoch 51/100\n",
      "116/116 [==============================] - 4s 39ms/step - loss: 1.4284 - accuracy: 0.5593 - val_loss: 1.1076 - val_accuracy: 0.6289\n",
      "Epoch 52/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 1.4182 - accuracy: 0.5623 - val_loss: 1.4003 - val_accuracy: 0.5897\n",
      "Epoch 53/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 1.4701 - accuracy: 0.5430 - val_loss: 1.5548 - val_accuracy: 0.5661\n",
      "Epoch 54/100\n",
      "116/116 [==============================] - 5s 40ms/step - loss: 1.4895 - accuracy: 0.5444 - val_loss: 1.1442 - val_accuracy: 0.6233\n",
      "Epoch 55/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 1.4290 - accuracy: 0.5574 - val_loss: 1.0972 - val_accuracy: 0.6166\n",
      "Epoch 56/100\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 1.4218 - accuracy: 0.5612 - val_loss: 1.0439 - val_accuracy: 0.6536\n",
      "Epoch 57/100\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 1.3660 - accuracy: 0.5797 - val_loss: 0.9836 - val_accuracy: 0.6726\n",
      "Epoch 58/100\n",
      "116/116 [==============================] - 4s 39ms/step - loss: 1.3707 - accuracy: 0.5743 - val_loss: 1.0834 - val_accuracy: 0.6525\n",
      "Epoch 59/100\n",
      "116/116 [==============================] - 4s 37ms/step - loss: 1.3498 - accuracy: 0.5832 - val_loss: 1.0320 - val_accuracy: 0.6491\n",
      "Epoch 60/100\n",
      "116/116 [==============================] - 5s 40ms/step - loss: 1.3803 - accuracy: 0.5775 - val_loss: 1.2090 - val_accuracy: 0.6143\n",
      "Epoch 61/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 1.3416 - accuracy: 0.5808 - val_loss: 0.9922 - val_accuracy: 0.6547\n",
      "Epoch 62/100\n",
      "116/116 [==============================] - 5s 40ms/step - loss: 1.2914 - accuracy: 0.5906 - val_loss: 0.9367 - val_accuracy: 0.6749\n",
      "Epoch 63/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 1.3087 - accuracy: 0.5954 - val_loss: 0.9402 - val_accuracy: 0.6794\n",
      "Epoch 64/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 1.3009 - accuracy: 0.5979 - val_loss: 0.9475 - val_accuracy: 0.6771\n",
      "Epoch 65/100\n",
      "116/116 [==============================] - 5s 40ms/step - loss: 1.3029 - accuracy: 0.5944 - val_loss: 0.8963 - val_accuracy: 0.6951\n",
      "Epoch 66/100\n",
      "116/116 [==============================] - 5s 40ms/step - loss: 1.2545 - accuracy: 0.6063 - val_loss: 0.9550 - val_accuracy: 0.6749\n",
      "Epoch 67/100\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 1.2546 - accuracy: 0.6144 - val_loss: 0.8860 - val_accuracy: 0.6951\n",
      "Epoch 68/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 1.3271 - accuracy: 0.5995 - val_loss: 0.8912 - val_accuracy: 0.7007\n",
      "Epoch 69/100\n",
      "116/116 [==============================] - 5s 40ms/step - loss: 1.2768 - accuracy: 0.6112 - val_loss: 0.9138 - val_accuracy: 0.6883\n",
      "Epoch 70/100\n",
      "116/116 [==============================] - 5s 40ms/step - loss: 1.2709 - accuracy: 0.6058 - val_loss: 0.8830 - val_accuracy: 0.7152\n",
      "Epoch 71/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 1.2546 - accuracy: 0.6098 - val_loss: 0.8995 - val_accuracy: 0.7040\n",
      "Epoch 72/100\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 1.3083 - accuracy: 0.5973 - val_loss: 0.8780 - val_accuracy: 0.7063\n",
      "Epoch 73/100\n",
      "116/116 [==============================] - 4s 37ms/step - loss: 1.2920 - accuracy: 0.6014 - val_loss: 0.8964 - val_accuracy: 0.7152\n",
      "Epoch 74/100\n",
      "116/116 [==============================] - 4s 39ms/step - loss: 1.2331 - accuracy: 0.6220 - val_loss: 0.9007 - val_accuracy: 0.7231\n",
      "Epoch 75/100\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 1.2700 - accuracy: 0.6115 - val_loss: 0.8662 - val_accuracy: 0.7343\n",
      "Epoch 76/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 1.2900 - accuracy: 0.6098 - val_loss: 0.8743 - val_accuracy: 0.7007\n",
      "Epoch 77/100\n",
      "116/116 [==============================] - 4s 37ms/step - loss: 1.2830 - accuracy: 0.6144 - val_loss: 0.8752 - val_accuracy: 0.7018\n",
      "Epoch 78/100\n",
      "116/116 [==============================] - 5s 40ms/step - loss: 1.2693 - accuracy: 0.6166 - val_loss: 2.9536 - val_accuracy: 0.3397\n",
      "Epoch 79/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 1.7645 - accuracy: 0.5031 - val_loss: 1.5973 - val_accuracy: 0.5269\n",
      "Epoch 80/100\n",
      "116/116 [==============================] - 4s 37ms/step - loss: 1.4906 - accuracy: 0.5618 - val_loss: 1.1566 - val_accuracy: 0.6457\n",
      "Epoch 81/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 1.3961 - accuracy: 0.5781 - val_loss: 1.0670 - val_accuracy: 0.6592\n",
      "Epoch 82/100\n",
      "116/116 [==============================] - 4s 39ms/step - loss: 1.3564 - accuracy: 0.5870 - val_loss: 0.9561 - val_accuracy: 0.6951\n",
      "Epoch 83/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 1.7814 - accuracy: 0.4909 - val_loss: 8.8105 - val_accuracy: 0.1244\n",
      "Epoch 84/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 1.7831 - accuracy: 0.4681 - val_loss: 4.5347 - val_accuracy: 0.1648\n",
      "Epoch 85/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 1.6306 - accuracy: 0.5126 - val_loss: 4.3897 - val_accuracy: 0.2007\n",
      "Epoch 86/100\n",
      "116/116 [==============================] - 4s 37ms/step - loss: 1.5776 - accuracy: 0.5265 - val_loss: 2.7963 - val_accuracy: 0.3094\n",
      "Epoch 87/100\n",
      "116/116 [==============================] - 5s 40ms/step - loss: 1.7114 - accuracy: 0.4966 - val_loss: 2.9802 - val_accuracy: 0.3161\n",
      "Epoch 88/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 1.7288 - accuracy: 0.4898 - val_loss: 5.6374 - val_accuracy: 0.2276\n",
      "Epoch 89/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 1.8684 - accuracy: 0.4638 - val_loss: 3.9588 - val_accuracy: 0.3621\n",
      "Epoch 90/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 1.6944 - accuracy: 0.5053 - val_loss: 2.4313 - val_accuracy: 0.4742\n",
      "Epoch 91/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 1.5697 - accuracy: 0.5286 - val_loss: 1.5740 - val_accuracy: 0.5078\n",
      "Epoch 92/100\n",
      "116/116 [==============================] - 4s 37ms/step - loss: 1.5464 - accuracy: 0.5441 - val_loss: 1.2844 - val_accuracy: 0.5908\n",
      "Epoch 93/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 1.5768 - accuracy: 0.5305 - val_loss: 1.2147 - val_accuracy: 0.5863\n",
      "Epoch 94/100\n",
      "116/116 [==============================] - 4s 39ms/step - loss: 1.4776 - accuracy: 0.5561 - val_loss: 1.1350 - val_accuracy: 0.6278\n",
      "Epoch 95/100\n",
      "116/116 [==============================] - 4s 37ms/step - loss: 1.4463 - accuracy: 0.5645 - val_loss: 1.0123 - val_accuracy: 0.6951\n",
      "Epoch 96/100\n",
      "116/116 [==============================] - 5s 39ms/step - loss: 1.4346 - accuracy: 0.5683 - val_loss: 1.1147 - val_accuracy: 0.6379\n",
      "Epoch 97/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 1.5876 - accuracy: 0.5257 - val_loss: 1.1524 - val_accuracy: 0.6357\n",
      "Epoch 98/100\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 1.5521 - accuracy: 0.5330 - val_loss: 1.3437 - val_accuracy: 0.5628\n",
      "Epoch 99/100\n",
      "116/116 [==============================] - 5s 39ms/step - loss: 1.4865 - accuracy: 0.5444 - val_loss: 1.1121 - val_accuracy: 0.6256\n",
      "Epoch 100/100\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 1.4629 - accuracy: 0.5620 - val_loss: 1.0151 - val_accuracy: 0.6547\n"
     ]
    }
   ],
   "source": [
    "callbacks_pretrained = []\n",
    "\n",
    "save_best_callback = tf.keras.callbacks.ModelCheckpoint(f'pretrainde_model_weights.hdf5', save_best_only=True, verbose=0)\n",
    "callbacks_pretrained.append(save_best_callback)\n",
    "\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(patience=25, restore_best_weights=True, verbose=0)\n",
    "callbacks_pretrained.append(early_stop_callback)\n",
    "\n",
    "history_pretrained = model.fit(train_dataset_rgb,\n",
    "                              validation_data=validation_dataset_rgb,\n",
    "                              steps_per_epoch=len(train_dataset_rgb),\n",
    "                              epochs=100,\n",
    "                              validation_steps=len(validation_dataset_rgb),\n",
    "                              verbose=1,\n",
    "                              callbacks=callbacks_pretrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55db480f-90b4-4def-b303-eeed98f173ab",
   "metadata": {},
   "source": [
    "We can see that the accuracy stops improving at around 61%. Then we witness overfitting. That suggests the algorithm could be optimized better for use with a pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16d8e555-c1b1-4755-b195-d8bc6f0fcf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 2s 21ms/step - loss: 1.0845 - accuracy: 0.6560\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_dataset_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a730dc-9915-4670-84fa-3744448894c2",
   "metadata": {},
   "source": [
    "The accuracy is slightly higher than than of our training dataset. Despite the quite lower accuracy, ~65% is quite a commendable amount considering half our weights are not trainable and the pretrained dataset propably is not comparable to our data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
